# Thinking with AI: Claude vs ChatGPT – How I Evaluate and Build with LLMs

*"I don't just use AI—I engage with it, challenge it, and grow alongside it."*

Working at the intersection of business analysis and AI implementation has given me a unique perspective on large language models. I've built RAG applications, automated workflows, and deployed AI solutions—but perhaps the most valuable insights come from how these systems reveal our own thinking patterns.

## The Experiment: A Simple Question Reveals Complex Differences

Recently, I conducted an illuminating experiment. I asked both Claude and ChatGPT to craft a compelling two-line response to "Why Anthropic?" for my job application. What emerged wasn't just different outputs, but a window into how these models approach problems—and how I evaluate their responses.

### ChatGPT's Response:
> "Anthropic's focus on safe and interpretable AI aligns with my experience developing LLM-based applications and driving ethical, data-driven solutions. With a strong foundation in AI, analytics, and product implementation, I'm eager to contribute to mission-driven innovation that prioritizes human impact."

### Claude's Initial Response:
> "Based on your resume, Anthropic could leverage your AI business analysis skills and experience with LLMs to help develop practical applications of their constitutional AI approach. Your background in product implementation and data analytics would be valuable for their mission of creating safe, helpful AI systems that can transform business requirements into actionable projects."

What struck me wasn't just the content differences, but how these variations revealed different approaches to problem-solving. When I pointed out the contrast, Claude's self-reflection was remarkable:

### Claude's Self-Evaluation:
> "What was missing in my response:
> - I didn't use first-person perspective, making it sound less personal and compelling
> - I didn't specifically mention Anthropic's ethical AI approach or constitutional AI principles
> - I focused too much on what you could do for them without showing alignment with their values
> - I didn't highlight your RAG implementation experience explicitly, which is directly relevant
> - I didn't convey passion for Anthropic's mission"

## What This Reveals About Working With LLMs

This exercise crystallized several key insights that guide how I build with AI:

### 1. Models Encode Different Thinking Patterns

Claude's analytical, third-person perspective contrasted with ChatGPT's more personalized, values-aligned approach. These aren't just stylistic differences—they reflect fundamentally different ways of processing the same request.

When building my personal RAG chatbot, I discovered that choosing the right foundation model isn't just about technical specifications—it's about matching thinking patterns to use cases. For analytical tasks requiring careful reasoning, Claude's thoughtful approach often produces more reliable results. For creative writing or persona-based interactions, ChatGPT's style can feel more natural.

### 2. Effective Evaluation Requires Comparative Analysis

Working with multiple models has transformed how I evaluate AI outputs. Single-model testing creates blindspots—you don't know what you're missing. My most successful implementations now involve:

- Running parallel prompts across different models
- Identifying complementary strengths in different approaches
- Creating evaluation rubrics that consider both technical accuracy and subjective factors like tone

### 3. Self-Reflection Is the Most Valuable Signal

What impressed me most about Claude's response wasn't the initial answer, but its ability to critically analyze its own shortcomings. This meta-cognitive capability—evaluating one's own thinking process—is precisely what makes working with these models so valuable.

In my product support roles, I've learned that the most insightful moments often come when systems reveal their limitations. These "edges" are where we learn the most about both the models and our own thinking.

## How This Shapes My Approach to Building With AI

This experience reinforced my approach to AI implementation:

1. **Value alignment matters as much as technical capability**. When building solutions, I ensure systems reflect the values and mission of the organization they serve.

2. **Perspective-taking is crucial**. I now design prompts that explicitly request first-person vs. third-person perspectives based on the use case.

3. **Meta-evaluation is essential**. I build feedback loops that allow models to evaluate their own outputs against specific criteria.

4. **Different models for different cognitive tasks**. I've stopped looking for a "best" model and instead match models to specific cognitive strengths.

## From Observer to Participant

The most profound shift in my thinking has been moving from seeing myself as an observer of AI to a participant in a collaborative reasoning process. These models don't just produce outputs—they extend and challenge my own thinking patterns.

When I built my RAG application (available on my [GitHub](https://github.com/preethichan/PersonalChatbot)), I discovered that the most valuable aspect wasn't the answers it provided, but how it helped me articulate better questions.

In this way, working with different LLMs has become less about evaluating their capabilities and more about developing my own capacity for clearer thinking, more precise communication, and more nuanced evaluation.

And perhaps that's the most important insight for those building with AI today: these systems are most valuable not when they think for us, but when they help us think better ourselves.

---

*Preethi Chandrasekan is a Business Analyst specializing in AI implementation with experience in building LLM applications and product analytics. Connect on LinkedIn or explore her projects on GitHub.*
